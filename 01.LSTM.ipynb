{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Downloading numpy-2.2.5-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Downloading numpy-2.2.5-cp313-cp313-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/12.6 MB 433.0 kB/s eta 0:00:28\n",
      "   - -------------------------------------- 0.5/12.6 MB 433.0 kB/s eta 0:00:28\n",
      "   -- ------------------------------------- 0.8/12.6 MB 518.0 kB/s eta 0:00:23\n",
      "   -- ------------------------------------- 0.8/12.6 MB 518.0 kB/s eta 0:00:23\n",
      "   -- ------------------------------------- 0.8/12.6 MB 518.0 kB/s eta 0:00:23\n",
      "   ---- ----------------------------------- 1.3/12.6 MB 630.1 kB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 1.3/12.6 MB 630.1 kB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 1.3/12.6 MB 630.1 kB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 1.3/12.6 MB 630.1 kB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 1.3/12.6 MB 630.1 kB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 1.3/12.6 MB 630.1 kB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 1.8/12.6 MB 564.4 kB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 1.8/12.6 MB 564.4 kB/s eta 0:00:20\n",
      "   ------ --------------------------------- 2.1/12.6 MB 569.2 kB/s eta 0:00:19\n",
      "   ------ --------------------------------- 2.1/12.6 MB 569.2 kB/s eta 0:00:19\n",
      "   ------ --------------------------------- 2.1/12.6 MB 569.2 kB/s eta 0:00:19\n",
      "   ------- -------------------------------- 2.4/12.6 MB 537.1 kB/s eta 0:00:20\n",
      "   -------- ------------------------------- 2.6/12.6 MB 555.2 kB/s eta 0:00:19\n",
      "   -------- ------------------------------- 2.6/12.6 MB 555.2 kB/s eta 0:00:19\n",
      "   --------- ------------------------------ 2.9/12.6 MB 576.0 kB/s eta 0:00:17\n",
      "   --------- ------------------------------ 2.9/12.6 MB 576.0 kB/s eta 0:00:17\n",
      "   --------- ------------------------------ 3.1/12.6 MB 578.5 kB/s eta 0:00:17\n",
      "   --------- ------------------------------ 3.1/12.6 MB 578.5 kB/s eta 0:00:17\n",
      "   --------- ------------------------------ 3.1/12.6 MB 578.5 kB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 3.4/12.6 MB 564.7 kB/s eta 0:00:17\n",
      "   ----------- ---------------------------- 3.7/12.6 MB 573.8 kB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 3.7/12.6 MB 573.8 kB/s eta 0:00:16\n",
      "   ------------ --------------------------- 3.9/12.6 MB 586.0 kB/s eta 0:00:15\n",
      "   ------------ --------------------------- 3.9/12.6 MB 586.0 kB/s eta 0:00:15\n",
      "   ------------- -------------------------- 4.2/12.6 MB 590.0 kB/s eta 0:00:15\n",
      "   ------------- -------------------------- 4.2/12.6 MB 590.0 kB/s eta 0:00:15\n",
      "   ------------- -------------------------- 4.2/12.6 MB 590.0 kB/s eta 0:00:15\n",
      "   ------------- -------------------------- 4.2/12.6 MB 590.0 kB/s eta 0:00:15\n",
      "   -------------- ------------------------- 4.7/12.6 MB 591.7 kB/s eta 0:00:14\n",
      "   -------------- ------------------------- 4.7/12.6 MB 591.7 kB/s eta 0:00:14\n",
      "   -------------- ------------------------- 4.7/12.6 MB 591.7 kB/s eta 0:00:14\n",
      "   --------------- ------------------------ 5.0/12.6 MB 579.4 kB/s eta 0:00:14\n",
      "   --------------- ------------------------ 5.0/12.6 MB 579.4 kB/s eta 0:00:14\n",
      "   --------------- ------------------------ 5.0/12.6 MB 579.4 kB/s eta 0:00:14\n",
      "   --------------- ------------------------ 5.0/12.6 MB 579.4 kB/s eta 0:00:14\n",
      "   ---------------- ----------------------- 5.2/12.6 MB 554.7 kB/s eta 0:00:14\n",
      "   ----------------- ---------------------- 5.5/12.6 MB 563.8 kB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 5.5/12.6 MB 563.8 kB/s eta 0:00:13\n",
      "   ------------------ --------------------- 5.8/12.6 MB 571.2 kB/s eta 0:00:13\n",
      "   ------------------- -------------------- 6.0/12.6 MB 582.0 kB/s eta 0:00:12\n",
      "   ------------------- -------------------- 6.0/12.6 MB 582.0 kB/s eta 0:00:12\n",
      "   ------------------- -------------------- 6.3/12.6 MB 578.3 kB/s eta 0:00:11\n",
      "   ------------------- -------------------- 6.3/12.6 MB 578.3 kB/s eta 0:00:11\n",
      "   -------------------- ------------------- 6.6/12.6 MB 583.1 kB/s eta 0:00:11\n",
      "   -------------------- ------------------- 6.6/12.6 MB 583.1 kB/s eta 0:00:11\n",
      "   --------------------- ------------------ 6.8/12.6 MB 583.1 kB/s eta 0:00:10\n",
      "   --------------------- ------------------ 6.8/12.6 MB 583.1 kB/s eta 0:00:10\n",
      "   --------------------- ------------------ 6.8/12.6 MB 583.1 kB/s eta 0:00:10\n",
      "   --------------------- ------------------ 6.8/12.6 MB 583.1 kB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 7.1/12.6 MB 572.1 kB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 7.3/12.6 MB 579.9 kB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 7.3/12.6 MB 579.9 kB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 7.3/12.6 MB 579.9 kB/s eta 0:00:10\n",
      "   ------------------------ --------------- 7.6/12.6 MB 572.4 kB/s eta 0:00:09\n",
      "   ------------------------ --------------- 7.6/12.6 MB 572.4 kB/s eta 0:00:09\n",
      "   ------------------------ --------------- 7.9/12.6 MB 573.4 kB/s eta 0:00:09\n",
      "   ------------------------ --------------- 7.9/12.6 MB 573.4 kB/s eta 0:00:09\n",
      "   ------------------------ --------------- 7.9/12.6 MB 573.4 kB/s eta 0:00:09\n",
      "   ------------------------- -------------- 8.1/12.6 MB 564.7 kB/s eta 0:00:08\n",
      "   ------------------------- -------------- 8.1/12.6 MB 564.7 kB/s eta 0:00:08\n",
      "   ------------------------- -------------- 8.1/12.6 MB 564.7 kB/s eta 0:00:08\n",
      "   -------------------------- ------------- 8.4/12.6 MB 561.9 kB/s eta 0:00:08\n",
      "   -------------------------- ------------- 8.4/12.6 MB 561.9 kB/s eta 0:00:08\n",
      "   --------------------------- ------------ 8.7/12.6 MB 561.5 kB/s eta 0:00:08\n",
      "   --------------------------- ------------ 8.7/12.6 MB 561.5 kB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 8.9/12.6 MB 560.8 kB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 8.9/12.6 MB 560.8 kB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 8.9/12.6 MB 560.8 kB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 9.2/12.6 MB 559.9 kB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 9.2/12.6 MB 559.9 kB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 9.4/12.6 MB 559.0 kB/s eta 0:00:06\n",
      "   ------------------------------ --------- 9.7/12.6 MB 565.0 kB/s eta 0:00:06\n",
      "   ------------------------------ --------- 9.7/12.6 MB 565.0 kB/s eta 0:00:06\n",
      "   ------------------------------- -------- 10.0/12.6 MB 563.8 kB/s eta 0:00:05\n",
      "   ------------------------------- -------- 10.0/12.6 MB 563.8 kB/s eta 0:00:05\n",
      "   ------------------------------- -------- 10.0/12.6 MB 563.8 kB/s eta 0:00:05\n",
      "   -------------------------------- ------- 10.2/12.6 MB 558.8 kB/s eta 0:00:05\n",
      "   -------------------------------- ------- 10.2/12.6 MB 558.8 kB/s eta 0:00:05\n",
      "   -------------------------------- ------- 10.2/12.6 MB 558.8 kB/s eta 0:00:05\n",
      "   --------------------------------- ------ 10.5/12.6 MB 557.3 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 560.9 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 560.9 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 560.9 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 11.0/12.6 MB 559.1 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 11.0/12.6 MB 559.1 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 11.0/12.6 MB 559.1 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 11.3/12.6 MB 554.2 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 11.3/12.6 MB 554.2 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 11.3/12.6 MB 554.2 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 11.5/12.6 MB 551.7 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 11.8/12.6 MB 558.2 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 12.1/12.6 MB 563.3 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 12.1/12.6 MB 563.3 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 12.1/12.6 MB 563.3 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 12.3/12.6 MB 558.7 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.3/12.6 MB 558.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.6 MB 564.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 560.1 kB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-2.2.5\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "AXFGmI5DiJht",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7XUdlvhSiQMh"
   },
   "outputs": [],
   "source": [
    "you = np.array([1,0,0,0,0,0,0])\n",
    "coffee = np.array([0,1,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-eI_d-BJia_H",
    "outputId": "51ea4441-d99d-4d9b-ba12-f6f4d50da995"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3 0.1 0.1]\n",
      " [0.7 0.7 0.7]\n",
      " [0.7 0.8 0.3]\n",
      " [0.6 0.1 0.1]\n",
      " [0.6 0.3 1. ]\n",
      " [0.6 0.7 0.6]\n",
      " [0.3 0.4 0.2]]\n"
     ]
    }
   ],
   "source": [
    "W1 = np.array([\n",
    "    [0.3,0.1,0.1],\n",
    "    [0.7,0.7,0.7],\n",
    "    [0.7,0.8,0.3],\n",
    "    [0.6,0.1,0.1],\n",
    "    [0.6,0.3,1.0],\n",
    "    [0.6,0.7,0.6],\n",
    "    [0.3,0.4,0.2]\n",
    "])\n",
    "print(W1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "58FMtgzzi4dw",
    "outputId": "0d74713c-5395-431c-af79-42ea6af379f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3 0.1 0.1]\n"
     ]
    }
   ],
   "source": [
    "h1 = you@W1\n",
    "print(h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DXYnWo65i_af",
    "outputId": "f24a1729-b97d-418b-f4b2-02d1a9bc0e85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7 0.7 0.7]\n"
     ]
    }
   ],
   "source": [
    "h2 = coffee@W1\n",
    "print(h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N5xbLOaqi_lz",
    "outputId": "681135f1-20ae-4026-ac1f-3d7e83804f1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5 0.4 0.4]\n"
     ]
    }
   ],
   "source": [
    "h = (h1 + h2)/2\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "eSI0tYOgnLZw"
   },
   "outputs": [],
   "source": [
    "W2 = np.array([\n",
    "    [0.2,0.2,0.1,0.6,0.7,0.1,0.5],\n",
    "    [0.2,0.1,0.5,0.2,0.2,0.2,0.3],\n",
    "    [0.6,0.1,0.4,0.2,0.8,0.8,0.0]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l3ImKGqVndK4",
    "outputId": "9dfea967-27cb-456b-a0c0-b8aaabab7fd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2 0.2 0.6]\n",
      " [0.2 0.1 0.1]\n",
      " [0.1 0.5 0.4]\n",
      " [0.6 0.2 0.2]\n",
      " [0.7 0.2 0.8]\n",
      " [0.1 0.2 0.8]\n",
      " [0.5 0.3 0. ]]\n"
     ]
    }
   ],
   "source": [
    "print(W2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gqldm6UHnfWn",
    "outputId": "bc31d2d1-d7e3-4156-d6b7-5121bcd5b921"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.42, 0.18, 0.41, 0.46, 0.75, 0.45, 0.37])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2.T@h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nEy7EMc5nhxm",
    "outputId": "368ac18f-4170-4e88-ad9b-90b3f769a498"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(W2.T@h, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gtcjjaIENtx7"
   },
   "source": [
    "# LSTM 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\user\\.conda\\envs\\jupyter_env\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: torch in c:\\users\\user\\.conda\\envs\\jupyter_env\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\user\\.conda\\envs\\jupyter_env\\lib\\site-packages (from pandas) (2.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\.conda\\envs\\jupyter_env\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\.conda\\envs\\jupyter_env\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\.conda\\envs\\jupyter_env\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\.conda\\envs\\jupyter_env\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\user\\.conda\\envs\\jupyter_env\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\user\\.conda\\envs\\jupyter_env\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\.conda\\envs\\jupyter_env\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\.conda\\envs\\jupyter_env\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\.conda\\envs\\jupyter_env\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\.conda\\envs\\jupyter_env\\lib\\site-packages (from torch) (78.1.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\.conda\\envs\\jupyter_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\.conda\\envs\\jupyter_env\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\.conda\\envs\\jupyter_env\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "CZJpGdx8NwLj"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "LFQGqaGCN9h4"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(777)\n",
    "\n",
    "# ===== 1. CSV에서 데이터 불러오기 =====\n",
    "df = pd.read_csv(\"./data/review_data.csv\", encoding='cp949')\n",
    "text = df[\"text\"].tolist()\n",
    "labels = df[\"labels\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "id": "Pljas8CrOCWB",
    "outputId": "9b03f95e-c545-4a19-df17-ebbaed968cae"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>배우들 연기도 너무 좋았어요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>스토리가 탄탄하고 연출도 훌륭했어요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>정말 감동적인 영화였습니다. 눈물이 멈추질 않았어요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>끝까지 집중해서 봤습니다. 완전 추천해요!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>감성과 메시지가 모두 살아있는 영화였어요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>오랜만에 이런 좋은 영화를 봐서 기분이 좋아요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>음악, 연출, 연기 모두 완벽했어요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>시간 가는 줄 몰랐어요. 최고의 영화!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>스토리 전개가 매끄럽고 감동적이었어요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>친구들에게 꼭 추천하고 싶은 영화예요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>지루해서 중간에 졸았어요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>배우 연기가 너무 어색해서 몰입이 안 됐어요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>스토리가 산만하고 전개가 엉성해요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>예고편이 다였네요. 본편은 별로예요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>너무 뻔한 이야기라 재미가 없었어요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>연출이 허술하고 대사도 부자연스러워요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>기대한 만큼 실망만 컸어요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>시간 아깝고 돈 아깝네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>한 번 보고 다시는 보고 싶지 않아요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>결말도 어이없고 전체적으로 별로였어요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             text  labels\n",
       "0                배우들 연기도 너무 좋았어요.       1\n",
       "1            스토리가 탄탄하고 연출도 훌륭했어요.       1\n",
       "2   정말 감동적인 영화였습니다. 눈물이 멈추질 않았어요.       1\n",
       "3         끝까지 집중해서 봤습니다. 완전 추천해요!       1\n",
       "4         감성과 메시지가 모두 살아있는 영화였어요.       1\n",
       "5      오랜만에 이런 좋은 영화를 봐서 기분이 좋아요.       1\n",
       "6            음악, 연출, 연기 모두 완벽했어요.       1\n",
       "7           시간 가는 줄 몰랐어요. 최고의 영화!       1\n",
       "8           스토리 전개가 매끄럽고 감동적이었어요.       1\n",
       "9           친구들에게 꼭 추천하고 싶은 영화예요.       1\n",
       "10                 지루해서 중간에 졸았어요.       0\n",
       "11      배우 연기가 너무 어색해서 몰입이 안 됐어요.       0\n",
       "12            스토리가 산만하고 전개가 엉성해요.       0\n",
       "13           예고편이 다였네요. 본편은 별로예요.       0\n",
       "14           너무 뻔한 이야기라 재미가 없었어요.       0\n",
       "15          연출이 허술하고 대사도 부자연스러워요.       0\n",
       "16                기대한 만큼 실망만 컸어요.       0\n",
       "17                 시간 아깝고 돈 아깝네요.       0\n",
       "18          한 번 보고 다시는 보고 싶지 않아요.       0\n",
       "19          결말도 어이없고 전체적으로 별로였어요.       0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4TNoydI0OERy",
    "outputId": "175addf7-cc4f-4bdf-e7df-03efb48f14b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['배우들', '연기도', '너무', '좋았어요.'],\n",
       " ['스토리가', '탄탄하고', '연출도', '훌륭했어요.'],\n",
       " ['정말', '감동적인', '영화였습니다.', '눈물이', '멈추질', '않았어요.'],\n",
       " ['끝까지', '집중해서', '봤습니다.', '완전', '추천해요!'],\n",
       " ['감성과', '메시지가', '모두', '살아있는', '영화였어요.'],\n",
       " ['오랜만에', '이런', '좋은', '영화를', '봐서', '기분이', '좋아요.'],\n",
       " ['음악,', '연출,', '연기', '모두', '완벽했어요.'],\n",
       " ['시간', '가는', '줄', '몰랐어요.', '최고의', '영화!'],\n",
       " ['스토리', '전개가', '매끄럽고', '감동적이었어요.'],\n",
       " ['친구들에게', '꼭', '추천하고', '싶은', '영화예요.'],\n",
       " ['지루해서', '중간에', '졸았어요.'],\n",
       " ['배우', '연기가', '너무', '어색해서', '몰입이', '안', '됐어요.'],\n",
       " ['스토리가', '산만하고', '전개가', '엉성해요.'],\n",
       " ['예고편이', '다였네요.', '본편은', '별로예요.'],\n",
       " ['너무', '뻔한', '이야기라', '재미가', '없었어요.'],\n",
       " ['연출이', '허술하고', '대사도', '부자연스러워요.'],\n",
       " ['기대한', '만큼', '실망만', '컸어요.'],\n",
       " ['시간', '아깝고', '돈', '아깝네요.'],\n",
       " ['한', '번', '보고', '다시는', '보고', '싶지', '않아요.'],\n",
       " ['결말도', '어이없고', '전체적으로', '별로였어요.']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize = [sentence.split() for sentence in text]\n",
    "tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iIqJ2OHNTeTU",
    "outputId": "f989d769-0781-4698-def3-cb1656ac664d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'완전', '다였네요.', '영화였어요.', '실망만', '한', '중간에', '정말', '배우들', '감성과', '연출도', '아깝네요.', '음악,', '재미가', '가는', '영화!', '영화를', '연출이', '대사도', '없었어요.', '꼭', '기대한', '연기도', '별로였어요.', '영화였습니다.', '본편은', '연출,', '좋은', '싶지', '연기가', '됐어요.', '줄', '시간', '허술하고', '집중해서', '추천하고', '배우', '눈물이', '탄탄하고', '몰랐어요.', '기분이', '친구들에게', '만큼', '안', '봐서', '모두', '번', '별로예요.', '스토리가', '돈', '감동적인', '끝까지', '엉성해요.', '예고편이', '않았어요.', '결말도', '전개가', '훌륭했어요.', '살아있는', '부자연스러워요.', '어이없고', '최고의', '이런', '추천해요!', '컸어요.', '지루해서', '좋아요.', '뻔한', '아깝고', '싶은', '않아요.', '산만하고', '다시는', '멈추질', '좋았어요.', '감동적이었어요.', '메시지가', '몰입이', '오랜만에', '졸았어요.', '영화예요.', '스토리', '완벽했어요.', '보고', '연기', '어색해서', '봤습니다.', '매끄럽고', '너무', '이야기라', '전체적으로'}\n"
     ]
    }
   ],
   "source": [
    "def make_voka(tokenized_sentences):\n",
    "  voca = set()\n",
    "  for sentence in tokenized_sentences:\n",
    "    for word in sentence:\n",
    "      voca.add(word)\n",
    "  return voca\n",
    "\n",
    "voca = make_voka(tokenize)\n",
    "print(voca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VRUEejZGVAgJ",
    "outputId": "b0c527c9-9f9c-4e3c-d90e-0e6d8623fc84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'완전': 1, '다였네요.': 2, '영화였어요.': 3, '실망만': 4, '한': 5, '중간에': 6, '정말': 7, '배우들': 8, '감성과': 9, '연출도': 10, '아깝네요.': 11, '음악,': 12, '재미가': 13, '가는': 14, '영화!': 15, '영화를': 16, '연출이': 17, '대사도': 18, '없었어요.': 19, '꼭': 20, '기대한': 21, '연기도': 22, '별로였어요.': 23, '영화였습니다.': 24, '본편은': 25, '연출,': 26, '좋은': 27, '싶지': 28, '연기가': 29, '됐어요.': 30, '줄': 31, '시간': 32, '허술하고': 33, '집중해서': 34, '추천하고': 35, '배우': 36, '눈물이': 37, '탄탄하고': 38, '몰랐어요.': 39, '기분이': 40, '친구들에게': 41, '만큼': 42, '안': 43, '봐서': 44, '모두': 45, '번': 46, '별로예요.': 47, '스토리가': 48, '돈': 49, '감동적인': 50, '끝까지': 51, '엉성해요.': 52, '예고편이': 53, '않았어요.': 54, '결말도': 55, '전개가': 56, '훌륭했어요.': 57, '살아있는': 58, '부자연스러워요.': 59, '어이없고': 60, '최고의': 61, '이런': 62, '추천해요!': 63, '컸어요.': 64, '지루해서': 65, '좋아요.': 66, '뻔한': 67, '아깝고': 68, '싶은': 69, '않아요.': 70, '산만하고': 71, '다시는': 72, '멈추질': 73, '좋았어요.': 74, '감동적이었어요.': 75, '메시지가': 76, '몰입이': 77, '오랜만에': 78, '졸았어요.': 79, '영화예요.': 80, '스토리': 81, '완벽했어요.': 82, '보고': 83, '연기': 84, '어색해서': 85, '봤습니다.': 86, '매끄럽고': 87, '너무': 88, '이야기라': 89, '전체적으로': 90}\n"
     ]
    }
   ],
   "source": [
    "word2idx = {word: idx+1 for idx, word in enumerate(voca)} # padding = 0\n",
    "print(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zm70OdcQXG8k",
    "outputId": "75a385f2-270a-455b-8402-72e0e34687b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx.get('졸았어요.', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u-JKrIZzXKQw",
    "outputId": "3bf952eb-2eb3-41de-a476-4a4758bb244c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx.get('좋았어요.', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4n-CTBjwhd_a",
    "outputId": "22df0eae-b825-422a-e5f5-7303d1515336"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n"
     ]
    }
   ],
   "source": [
    "n_voca = len(word2idx) + 1\n",
    "print(n_voca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "_BVAScSXXQaH"
   },
   "outputs": [],
   "source": [
    "# ======= 3. Dataset 클래스 생성 =======\n",
    "class TextDataset(Dataset):\n",
    "  def __init__(self, text, labels, word2idx):\n",
    "    self.data = [sc.split() for sc in text]\n",
    "    self.labels = labels\n",
    "    self.word2idx = word2idx\n",
    "    self.max_len = max(len(sc) for sc in self.data)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    sentence = self.data[idx]\n",
    "    indices = [word2idx.get(word,0) for word in sentence]\n",
    "    padding = indices + [0] * (self.max_len - len(indices))\n",
    "    return torch.tensor(padding), torch.tensor(self.labels[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "E1FQ4sz1ZSqY"
   },
   "outputs": [],
   "source": [
    "dataset = TextDataset(text, labels, word2idx)\n",
    "loader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "XvuW3yvCZhD-"
   },
   "outputs": [],
   "source": [
    "# ======= 4. LSTM 모델 =======\n",
    "class LSTMClassifier(nn.Module):\n",
    "  def __init__(self, n_voca, embed_dim, hidden_dim, output_dim):\n",
    "    super().__init__()\n",
    "    self.embedding = nn.Embedding(n_voca, embed_dim, padding_idx=0)\n",
    "    self.lstm = nn.LSTM(\n",
    "        input_size = embed_dim,\n",
    "        hidden_size = hidden_dim,\n",
    "        num_layers = 2,\n",
    "        batch_first = True\n",
    "    )\n",
    "    self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "  def forward(self, x):\n",
    "    embedded = self.embedding(x)\n",
    "    _, (hidden, _) = self.lstm(embedded)\n",
    "    return self.fc(hidden[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "8hurvKVbbkcs"
   },
   "outputs": [],
   "source": [
    "model = LSTMClassifier(n_voca, embed_dim=16, hidden_dim=32, output_dim=2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XZMyB7UchKPB",
    "outputId": "2501c916-a148-4453-8d24-7a1718429ad4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5875\n",
      "Epoch 2, Loss: 0.6931\n",
      "Epoch 3, Loss: 0.7417\n",
      "Epoch 4, Loss: 0.9228\n",
      "Epoch 5, Loss: 0.0488\n",
      "Epoch 6, Loss: 0.0012\n",
      "Epoch 7, Loss: 0.0004\n",
      "Epoch 8, Loss: 0.0004\n",
      "Epoch 9, Loss: 0.0003\n",
      "Epoch 10, Loss: 0.0003\n"
     ]
    }
   ],
   "source": [
    "# ======= 5. 학습 =======\n",
    "for epoch in range(10):\n",
    "  for x_batch, y_batch in loader:\n",
    "    optimizer.zero_grad()\n",
    "    y_hat = model(x_batch)\n",
    "    loss = criterion(y_hat, y_batch)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "  print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "n-I3BZpoh7wj"
   },
   "outputs": [],
   "source": [
    "# ======= 6. 예측 =======\n",
    "def predict(sentence):\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    words = sentence.split()\n",
    "    indices = [word2idx.get(word, 0) for word in words]\n",
    "    padding = indices + [0] * (dataset.max_len - len(indices))\n",
    "    input_tensor = torch.tensor([padding])\n",
    "    output = model(input_tensor)\n",
    "    predicted = torch.argmax(output, dim=1).item()\n",
    "    return \"긍정\" if predicted == 1 else \"부정\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cq8XW-eLlZiM",
    "outputId": "65bb17c7-ac60-4cf4-8320-1f4ad269b5f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장: 정말 감동적인 영화였어 -> 예측: 긍정\n",
      "문장: 지루하고 재미없다 -> 예측: 긍정\n",
      "문장: 다시 보고 싶어 -> 예측: 부정\n",
      "문장: 정말 별로 재미없어. 졸았어 -> 예측: 긍정\n"
     ]
    }
   ],
   "source": [
    "# ======= 7. 예측 테스트 =======\n",
    "test_sentences = [\n",
    "    \"정말 감동적인 영화였어\",\n",
    "    \"지루하고 재미없다\",\n",
    "    \"다시 보고 싶어\",\n",
    "    \"정말 별로 재미없어. 졸았어\"\n",
    "]\n",
    "\n",
    "for sentence in test_sentences:\n",
    "  print(f\"문장: {sentence} -> 예측: {predict(sentence)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hZGfUQXNl1qB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
